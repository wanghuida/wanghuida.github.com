<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Mogilefs | 惠达的小宅]]></title>
  <link href="http://www.wanghd.com/blog/categories/mogilefs/atom.xml" rel="self"/>
  <link href="http://www.wanghd.com/"/>
  <updated>2012-11-09T17:42:31+08:00</updated>
  <id>http://www.wanghd.com/</id>
  <author>
    <name><![CDATA[王惠达 huida wanghuida]]></name>
    <email><![CDATA[wanghuida258@yahoo.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[perl父进程监听，子进程工作实例]]></title>
    <link href="http://www.wanghd.com/blog/2012/11/08/perlfu-jin-cheng-jian-ting-zi-jin-cheng-gong-zuo-shi-li/"/>
    <updated>2012-11-08T22:15:00+08:00</updated>
    <id>http://www.wanghd.com/blog/2012/11/08/perlfu-jin-cheng-jian-ting-zi-jin-cheng-gong-zuo-shi-li</id>
    <content type="html"><![CDATA[<ol>
<li>构造后台进程</li>
<li>主进程监到连接，创建子进程接收消息并处理消息</li>
<li>主进程继续监听，同时非阻塞的回收子进程</li>
</ol>


<!-- more -->


<p>```perl</p>

<h1>!/usr/bin/perl</h1>

<p>use warnings;
use strict;
use IO::Socket;
use Socket qw(SO_KEEPALIVE);
use IO::Poll;</p>

<h1>POSIX标准是必须要的，否则waitpid会阻塞住</h1>

<p>use POSIX;
use Carp;
use Errno  qw(EINPROGRESS EWOULDBLOCK EISCONN ENOTSOCK</p>

<pre><code>          EPIPE EAGAIN EBADF ECONNRESET ENOPROTOOPT);
</code></pre>

<p>$| = 1;
daemonize();</p>

<p>my $server = IO::Socket::INET->new(LocalAddr => "0.0.0.0:5678",</p>

<pre><code>                               Type      =&gt; SOCK_STREAM,
                               Proto     =&gt; 'tcp',
                               Blocking  =&gt; 0,
                               Reuse     =&gt; 1,
                               Listen    =&gt; 1024 )
or die "Error creating socket: $@\n";
</code></pre>

<p>$server->sockopt(SO_KEEPALIVE, 1);</p>

<p>while(1) {</p>

<pre><code>while(my $pid = waitpid -1, WNOHANG) {
    #print "child[$pid] closed\n" if($pid &gt; 0);
    last unless $pid &gt; 0;  
}

if(my $csock = $server-&gt;accept) {                                                                                                                           
    my $pid = fork;

    if($pid){
        close($csock);
        undef $csock;
    }else{
        $0 .= " [perl child]"; 
        while(1) {
            my $buf;
            my $len = sysread($csock, $buf, 1048576, 0);
            work($buf); 
            last if (!$len &amp;&amp; $! != EWOULDBLOCK);
        }
        exit 0;
    }
}
</code></pre>

<p>}</p>

<h1>子进程的工作</h1>

<p>sub work(){</p>

<pre><code>print @_."\n";
</code></pre>

<p>}</p>

<p>sub daemonize {</p>

<pre><code>my($pid, $sess_id, $i);

if ($pid = fork) { exit 0; }

croak "Cannot detach from controlling terminal"
    unless $sess_id = POSIX::setsid();

$SIG{'HUP'} = 'IGNORE';
if ($pid = fork) { exit 0; }

chdir "/";

umask 0;
</code></pre>

<p>}</p>

<p>```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[mogilefs删除队列]]></title>
    <link href="http://www.wanghd.com/blog/2012/11/06/mogilefsshan-chu-dui-lie/"/>
    <updated>2012-11-06T19:31:00+08:00</updated>
    <id>http://www.wanghd.com/blog/2012/11/06/mogilefsshan-chu-dui-lie</id>
    <content type="html"><![CDATA[<h3>遇到的问题</h3>

<ul>
<li>发现file_to_delete2队列表里有500万记录，奇怪这些文件为什么要删除？心里不踏实，寻找根源...</li>
<li>在队列中随便拿一个fid，在file表里查竟然是空的，再找file_on表竟然有数据...</li>
</ul>


<h3>什么时候会插入fid到删除队列呢</h3>

<ol>
<li>cmd_create_close时，如果连接终端，文件大小等不正确，会增加到删除队列</li>
<li>cmd_create_close时，如果同一domain下key已经存在，那么会去删除原有的文件(两份文件key相同，但是fid不同，我的问题就出在这)</li>
<li>mogdelete工具会删除memcache和file表的文件记录，并运用删除队列删除磁盘上的文件和file_on表</li>
<li>client调用delete方法，和mogdelete一样</li>
</ol>


<!-- more -->


<h3>cmd_create_close逻辑</h3>

<ul>
<li>mogilefs上传文件的逻辑是先问tracker拿文件存储路径，然后上传文件到一个storage，最后调用cmd_create_close方法插入数据记录和replicate队列</li>
</ul>


<p>```perl
sub cmd_create_close {</p>

<pre><code>my MogileFS::Worker::Query $self = shift;
my $args = shift;

# has to be filled out for some plugins
$args-&gt;{dmid} = $self-&gt;check_domain($args)
    or return $self-&gt;err_line('domain_not_found');

# call out to a hook that might modify the arguments for us
# 调用插件用的钩子，一般是没的
MogileFS::run_global_hook('cmd_create_close', $args);

# late validation of parameters
# 设置下面使用的变量
my $dmid  = $args-&gt;{dmid};
my $key   = $args-&gt;{key};
my $fidid = $args-&gt;{fid}    or return $self-&gt;err_line("no_fid");
my $devid = $args-&gt;{devid}  or return $self-&gt;err_line("no_devid");
my $path  = $args-&gt;{path}   or return $self-&gt;err_line("no_path");
my $checksum = $args-&gt;{checksum};

if ($checksum) {
    $checksum = eval { MogileFS::Checksum-&gt;from_string($fidid, $checksum) };
    return $self-&gt;err_line("invalid_checksum_format") if $@;
}    

# 初始化fid和dfid对象
my $fid  = MogileFS::FID-&gt;new($fidid);
my $dfid = MogileFS::DevFID-&gt;new($devid, $fid);

# is the provided path what we'd expect for this fid/devid?
# 验证是否为伪造路径
return $self-&gt;err_line("bogus_args")
    unless $path eq $dfid-&gt;url;
my $sto = Mgd::get_store();

# find the temp file we're closing and making real.  If another worker
# already has it, bail out---the client closed it twice.
# this is racy, but the only expected use case is a client retrying.
# should still be fixed better once more scalable locking is available.
# 取得零时文件数据,并删除掉
my $trow = $sto-&gt;delete_and_return_tempfile_row($fidid) or
    return $self-&gt;err_line("no_temp_file");

# Protect against leaving orphaned uploads.
# 定义错误函数，可以看到$fid-&gt;delete会删除file表记录并插入删除队列
my $failed = sub {
    $dfid-&gt;add_to_db;
    $fid-&gt;delete;
};

# 验证设备
unless ($trow-&gt;{devids} =~ m/\b$devid\b/) {
    $failed-&gt;();
    return $self-&gt;err_line("invalid_destdev", "File uploaded to invalid dest $devid. Valid devices were: " . $trow-&gt;{devids});
}

# if a temp file is closed without a provided-key, that means to
# delete it.
# 验证key
unless (defined $key &amp;&amp; length($key)) {
    $failed-&gt;();
    return $self-&gt;ok_line;
}

# get size of file and verify that it matches what we were given, if anything
my $httpfile = MogileFS::HTTPFile-&gt;at($path);
my $size = $httpfile-&gt;size;

# size check is optional? Needs to support zero byte files.
# 验证文件大小
$args-&gt;{size} = -1 unless $args-&gt;{size};
if (!defined($size) || $size == MogileFS::HTTPFile::FILE_MISSING) {
    # storage node is unreachable or the file is missing
    my $type    = defined $size ? "missing" : "cantreach";
    my $lasterr = MogileFS::Util::last_error();
    $failed-&gt;();
    return $self-&gt;err_line("size_verify_error", "Expected: $args-&gt;{size}; actual: 0 ($type); path: $path; error: $lasterr")
}

if ($args-&gt;{size} &gt; -1 &amp;&amp; ($args-&gt;{size} != $size)) {
    $failed-&gt;();
    return $self-&gt;err_line("size_mismatch", "Expected: $args-&gt;{size}; actual: $size; path: $path")
}

# checksum validation is optional as it can be very expensive
# However, we /always/ verify it if the client wants us to, even
# if the class does not enforce or store it.
# 校验和
if ($checksum &amp;&amp; $args-&gt;{checksumverify}) {
    my $alg = $checksum-&gt;hashname;
    my $actual = $httpfile-&gt;digest($alg, sub { $self-&gt;still_alive });
    if ($actual ne $checksum-&gt;{checksum}) {
        $failed-&gt;();
        $actual = "$alg:" . unpack("H*", $actual);
        return $self-&gt;err_line("checksum_mismatch",
                       "Expected: $checksum; actual: $actual; path: $path");
    }
}
# see if we have a fid for this key already
# 关键的来了，如果在同一个domain下有相同的key，那么删除该文件的file表记录，并插入delete队列
my $old_fid = MogileFS::FID-&gt;new_from_dmid_and_key($dmid, $key);
if ($old_fid) {
    # Fail if a file already exists for this fid.  Should never
    # happen, as it should not be possible to close a file twice.
    return $self-&gt;err_line("fid_exists")
        unless $old_fid-&gt;{fidid} != $fidid;

    $old_fid-&gt;delete;
}

# TODO: check for EIO?

# insert file_on row
# 以上都没有问题，那么就确认保存文件到数据库
# 保存到file_on表
$dfid-&gt;add_to_db;

$checksum-&gt;maybe_save($dmid, $trow-&gt;{classid}) if $checksum;

# 保存到file表 
$sto-&gt;replace_into_file(
                        fidid   =&gt; $fidid,
                        dmid    =&gt; $dmid,
                        key     =&gt; $key,
                        length  =&gt; $size,
                        classid =&gt; $trow-&gt;{classid},
                        devcount =&gt; 1,
                        );

# mark it as needing replicating:
# 插入文件到replicate队列 
$fid-&gt;enqueue_for_replication();

# call the hook - if this fails, we need to back the file out
# 调用钩子
my $rv = MogileFS::run_global_hook('file_stored', $args);
if (defined $rv &amp;&amp; ! $rv) { # undef = no hooks, 1 = success, 0 = failure
    $fid-&gt;delete;                                                                                                                                                           
    return $self-&gt;err_line("plugin_aborted");
}
# all went well, we would've hit condthrow on DB errors
# 返回正确结果
return $self-&gt;ok_line;
</code></pre>

<p>}  <br/>
```</p>

<h3>总结为什么会出现这种现象</h3>

<ul>
<li>当在同一个domain下，上传相同key的文件，之前的文件会被删除，但是两个文件的fid是不同的</li>
<li>$fid->delete这个操作实际是删除memcache和file表数据，file_on表和磁盘上的文件交给队列来处理</li>
<li>作者考虑到删除文件是比较耗时的操作，所以交给队列慢慢处理，才会导致file表里没数据，但是file_on上仍有数据</li>
<li>如果可能，尽量避免上传相同的key，这样可以减少对db的读写操作(我准备优化)</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MogileFS详解]]></title>
    <link href="http://www.wanghd.com/blog/2012/10/23/mogilefsxiang-jie/"/>
    <updated>2012-10-23T22:48:00+08:00</updated>
    <id>http://www.wanghd.com/blog/2012/10/23/mogilefsxiang-jie</id>
    <content type="html"><![CDATA[<ul>
<li>经过一个月的实际应用，我想是时候应该总结一下mogilefs的使用了，如果想和作者交流参考<a href="/blog/2012/10/13/irc-irssishi-yong-jiao-cheng/">IRC教程</a></li>
</ul>


<h3>MogileFS简介</h3>

<blockquote><p>MogileFS是一个<code>开源</code>的<code>分布式文件系统</code>，配合cdn和squid，性能非常好(<code>15亿</code>文件没问题，其他数据不方便透露)</p>

<p>他由下面几个部分组成:</p></blockquote>

<p><img src="/images/post/mogilefs-summary.jpg" title="mogilefs-summary" alt="mogilefs-summary" /></p>

<ol>
<li>memcache：用来缓存查询结果，降低db压力</li>
<li>mogilefsd：就是tracker，用来接收请求并交给子进程(job)处理</li>
<li>mogstored：监控磁盘状态和文件的实际存储</li>
<li>client：支持perl，java，ruby，php，python</li>
<li>mysql：存储记录</li>
<li>util：日常维护管理的工具集</li>
<li>telnet：监控tracker，实时调整job的工具</li>
</ol>


<!-- more -->


<h3>Mogstored</h3>

<blockquote><p>监控磁盘状态和文件的实际存储,启动mogstored会发现包含2个端口，默认的7501和7500</p>

<blockquote><p>7501用来监控磁盘状态</p>

<p>7500用来处理实际的文件存储</p></blockquote></blockquote>

<p><img src="/images/post/mogilefs-mogstored.jpg" title="mogilefs-mogstored" alt="mogilefs-mogstored" /></p>

<h4>问题总结</h4>

<ul>
<li>原本我一直以为mogstored自己实现了一套文件存储，但实际上不是。它使用的是WebDav，所以可以使用nginx代替默认的perlbal，实际用下来nginx更稳定</li>
<li>WebDav：一种基于 HTTP 1.1协议的通信协议.它扩展了HTTP 1.1，在GET、POST、HEAD等几个HTTP标准方法以外添加了一些新的方法，例如PUT(新增)、DELETE(删除)、MKCOL(创建目录)</li>
<li>在mogstored的使用上，犯过一个错误：直接使用root启动mogstored，那么创建的文件夹和文件都是属于root，导致delete job无法删除该文件（同事陈磊发现）</li>
<li>文件存储规则：/dev-xx/0/123/456/789/0123456789.fid，fid不足十位补0，通过fid进行切割变为目录，即分散又效率</li>
</ul>


<h3>Mogilefsd</h3>

<blockquote><p>主进程负责接受请求，分配任务给子进程执行,下面详细介绍一下他的子进程</p></blockquote>

<ol>
<li>query：处理主进程分配的请求，包括util和tool的指令</li>
<li>delete：根据删除队列对文件进行删除操作</li>
<li>replicate：复制文件直到满足mindevcount(文件复制几份)</li>
<li>fsck：检查磁盘文件和数据库是否匹配，不匹配时进行补救</li>
<li>monitor：监控子进程的状态，实时调整子进程个数</li>
<li>reaper：监控dead的磁盘，及时补救，把文件加到replicate queue</li>
<li>jobmaster：读取delete,replicate,rebalance,fsck队列，告诉主进程，主进程再交给对应的子进程处理</li>
</ol>


<h4>问题总结</h4>

<ul>
<li>query新建文件时，用剩余容量作权重，随机选择。所以新加入一块设备时，极有可能将成为热点设备，最好是一组设备一起加</li>
<li>如果设备出现问题，直接格式化后直接使用会导致数据库记录还在，文件丢失，最终fsck和replicate队列堆积，正确的做法是把设备状态设置为dead，然后格式化用一个新的devid使用</li>
<li>如果确定磁盘损坏，就一定要设置dead状态，reaper会自动补救</li>
</ul>


<h3>Memcache</h3>

<blockquote><p>用来缓存查询结果，降低db压力，query内部存放<code>key对应的fid</code>和<code>fid对应的设备</code></p></blockquote>

<h4>问题总结</h4>

<ul>
<li>db压力下不来的原因是客户端取得文件时没有设置noverify参数，如果确定要使用memcache就一定要设置noverify，否则不使用memcache</li>
</ul>


<h3>Mysql</h3>

<blockquote><p>用来存储记录，当然也可以使用其他数据库</p></blockquote>

<ol>
<li>host表：存储主机信息</li>
<li>device表：存储设备，一般单个device对应一块磁盘，也可以不这样</li>
<li>domain表：定义域，单个域下key唯一</li>
<li>class表：文件存放策略，包括份数，复制策略，校验和</li>
<li>server_settings表：部分配置信息和job配置信息</li>
<li>file表：文件信息</li>
<li>file_on表：文件存放在哪些存储设备</li>
<li>file_to_delete2表：删除队列表，升级后以前的不用了</li>
<li>file_to_queue表：type=1是fsck队列，type=2是rebalance队列</li>
<li>fsck_log表：fsck日志表，TYPE很多很诡异，参考<a href="/blog/2012/09/29/mogilefsde-fscktan-jiu/">fsk探究</a></li>
<li>file_to_replicate表：复制队列</li>
</ol>


<h4>问题总结</h4>

<ul>
<li>怀疑file_on表会有慢查询，其实不会太慢，因为Innodb默认asc排序</li>
</ul>


<p>```</p>

<h1>file_on的索引情况</h1>

<p>PRIMARY KEY (<code>fid</code>,<code>devid</code>),KEY <code>devid</code> (<code>devid</code>)</p>

<h1>下面的语句是不会慢的</h1>

<p>select * from file_on where devid = ? and fid > ? order by fid asc limit 100
```</p>

<ul>
<li>怀疑多个replicate队列同时操作同一个fid时是否会出现bug，其实不会，因为replicate使用mysql的get_lock(fid),release_lock(fid)</li>
</ul>


<h3>Utilities</h3>

<ol>
<li>mogadm：该工具直接管理mogilefs的主机、设备、域、类、从数据库、配置、fsck、rebalance</li>
<li>mogstat：观察fsck,rebalance,replication,delete运行状况</li>
<li>mogfiledebug：查看文件存储信息，也可以查file_on表</li>
<li>mogfetch：导出指定的文件</li>
<li>mogdelete：删除指定的文件</li>
<li>mogrename：更改文件的key</li>
<li>mogupload：插入一个文件</li>
<li>moglistfids，moglistkeys：批量列出记录，自己写脚本时可以使用</li>
</ol>


<h3>Telnet</h3>

<ol>
<li>!version：显示mogilefs版本</li>
<li>!recent：显示当前query执行时间（可做监控）</li>
<li>!queue：显示等待执行的查询（可做监控）</li>
<li>!stats：从tracker启动开始就记录的一些累加信息和实时信息，比如处理请求的总数、job队列当前记录数、当前等待执行的请求的个数等</li>
<li>!watch：显示<code>警告</code>和<code>错误</code>信息（可做监控）</li>
<li>!jobs：显示当前各个job的个数</li>
<li>!want：<code>动态调整</code>job个数</li>
<li>!to：不常用，向子进程发送消息，用来调试的</li>
<li>!shutdown：关闭所有mogilefsd进程</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MogileFS的replicate进程分析]]></title>
    <link href="http://www.wanghd.com/blog/2012/10/16/mogilefsde-replicatefen-xi/"/>
    <updated>2012-10-16T15:47:00+08:00</updated>
    <id>http://www.wanghd.com/blog/2012/10/16/mogilefsde-replicatefen-xi</id>
    <content type="html"><![CDATA[<h4>基本流程</h4>

<ol>
<li>从replicate queue里获取需要处理数据,进行循环</li>
<li>执行真正的【replicate操作】，操作时会锁住这个fid，然后返回结果【下面会对该操作具体分析】</li>
<li>返回没问题，删除队列并释放锁</li>
<li>返回failed_getting_lock说明正在处理了</li>
<li>返回no_source说明file_on表上没有关于该文件的记录，nexttry设置为最大并释放锁</li>
<li>返回too_happy说明devcount > mindevcount，会尝试删除多余的并释放锁（前提是文件存在，所以不会修复file_on有，文件丢失的情况）</li>
<li>如果以上都不满足，nexttry根据规则增加，failcount递增并释放锁</li>
</ol>


<h4>replicate操作分析</h4>

<ul>
<li>简单说replicate操作就是取得合适的device进行复制，合适的意思是尽量避免同一个host的device，没办法才用同一个host的device，有错误就返回具体信息</li>
<li>replicate操作才是真正的复制，代码比较多，但是不难理解（难点都会有注释）</li>
</ul>


<!-- more -->


<p>```perl
sub replicate {</p>

<pre><code>my ($fid, %opts) = @_;      #参数赋值
$fid = MogileFS::FID-&gt;new($fid) unless ref $fid;   #实例fid对象
my $fidid = $fid-&gt;id; #fid的id

debug("Replication for $fidid called, opts=".join(',',keys(%opts))) if $Mgd::DEBUG &gt;= 2;


my $errref    = delete $opts{'errref'};  #错误消息的引用
my $no_unlock = delete $opts{'no_unlock'};  #上锁,使用Mysql的锁,get_lock和release_lock
#复制源，复制到哪些设备，排除的设备，避免的设备
my $fixed_source = delete $opts{'source_devid'};
my $mask_devids  = delete $opts{'mask_devids'}  || {};
my $avoid_devids = delete $opts{'avoid_devids'} || {};
my $target_devids = delete $opts{'target_devids'} || []; # inverse of avoid_devids.
die "unknown_opts" if %opts;
die unless ref $mask_devids eq "HASH";

my $sdevid; #下面会看到，就是复制源

my $sto = Mgd::get_store();
#释放锁的函数release_lock(name)
my $unlock = sub {
    $sto-&gt;note_done_replicating($fidid);
};

#这是一个返回函数，返回结果用的
my $retunlock = sub {
    my $rv = shift;
    my ($errmsg, $errcode);
    if (@_ == 2) {
        ($errcode, $errmsg) = @_;
        $errmsg = "$errcode: $errmsg"; # include code with message
    } else {
        ($errmsg) = @_;
    }
    $$errref = $errcode if $errref;

    my $ret;
    if ($errcode &amp;&amp; $errcode eq "failed_getting_lock") {
        # don't emit a warning with error() on lock failure.  not
        # a big deal, don't scare people.
        $ret = 0;
    } else {
        $ret = $rv ? $rv : error($errmsg);
    }
    if ($no_unlock) {
        die "ERROR: must be called in list context w/ no_unlock" unless wantarray;
        return ($ret, $unlock);
    } else {
        die "ERROR: must not be called in list context w/o no_unlock" if wantarray;
        $unlock-&gt;();
        return $ret;
    }
};

# hashref of devid -&gt; MogileFS::Device所有的device
my $devs = Mgd::device_factory()-&gt;map_by_id
    or die "No device map";

#错误话就调用retunlock 
return $retunlock-&gt;(0, "failed_getting_lock", "Unable to obtain lock for fid $fidid")
    unless $sto-&gt;should_begin_replicating_fidid($fidid);#这里获取mysql的锁 get_lock(name,timeout),name里fidid

# if the fid doesn't even exist, consider our job done!  no point
# replicating file contents of a file no longer in the namespace.
#没有fid返回
return $retunlock-&gt;("nofid") unless $fid-&gt;exists;

#Class.pm对象
my $cls = $fid-&gt;class;
#策略对象MogileFS::ReplicationPolicy::MultipleHosts
my $polobj = $cls-&gt;repl_policy_obj;

# learn what this devices file is already on
#所有设备
my @on_devs;         # all devices fid is on, reachable or not.
#排除dead和drain的设备
my @on_devs_tellpol; # subset of @on_devs, to tell the policy class about
#可读的设备
my @on_up_devid;     # subset of @on_devs:  just devs that are readable
#设置上面的数组
foreach my $devid ($fid-&gt;devids) {
    my $d = Mgd::device_factory()-&gt;get_by_id($devid)
        or next;
    #fid在哪些dev上
    push @on_devs, $d;
    #should_hava_files表示状态不为drain或者dead
    if ($d-&gt;dstate-&gt;should_have_files &amp;&amp; ! $mask_devids-&gt;{$devid}) {
        push @on_devs_tellpol, $d;
    }
    #有read权限
    if ($d-&gt;dstate-&gt;can_read_from) {
        push @on_up_devid, $devid;
    }
}
#如果一个设备都没，就返回
return $retunlock-&gt;(0, "no_source",   "Source is no longer available replicating $fidid") if @on_devs == 0;
return $retunlock-&gt;(0, "source_down", "No alive devices available replicating $fidid") if @on_up_devid == 0;

#fixed_source设置错误，根本就没有
if ($fixed_source &amp;&amp; ! grep { $_ == $fixed_source } @on_up_devid) {
    error("Fixed source dev$fixed_source requested for $fidid but not available. Trying other devices");
}

#错误的设备记录，下面循环里就不会再使用了
my %dest_failed;    # devid -&gt; 1 for each devid we were asked to copy to, but failed.
my %source_failed;  # devid -&gt; 1 for each devid we had problems reading from.
#用来标记真的复制了，下面的循环会使用
my $got_copy_request = 0;  # true once replication policy asks us to move something somewhere
my $copy_err;

#过滤复制到哪些设备
my $dest_devs = $devs;
if (@$target_devids) {
    $dest_devs = {map { $_ =&gt; $devs-&gt;{$_} } @$target_devids};
}

my $rr;  #MogileFS::ReplicationRequest对象
#开始循环复制，因为会有可能要复制3份的嘛。
while (1) {
    #MogileFS::ReplicationPolicy::MultipleHosts的replicate_to
    #取得ReplicationRequest对象【该对象是通过ReplicationPolicy::MultipleHosts策略生成的】
    #该对象会有4种返回值，分别是，1：对象形式，说明需要并可以复制。2：tmp_no_answer，没有可选择的device。
    #3：all_good，一切OK。4：too_good，好过头了呀。
    $rr = rr_upgrade($polobj-&gt;replicate_to(
                                           fid       =&gt; $fidid, #fidid
                                           on_devs   =&gt; \@on_devs_tellpol, # all device objects fid is on, dead or otherwise
                                           all_devs  =&gt; $dest_devs, #所有的dev，如果有target_devids的话那就用target的咯
                                           failed    =&gt; \%dest_failed, #失败信息
                                           min       =&gt; $cls-&gt;mindevcount, #最小设备
                                           ));
    #是happy就跳出，跳出会有后续处理的
    last if $rr-&gt;is_happy;

    #经过过滤的dev
    my @ddevs;  # dest devs, in order of preference
    #选择出来的devid
    my $ddevid; # dest devid we've chosen to copy to
    #这里设置ddevs,其实就是host不同的设备
    if (@ddevs = $rr-&gt;copy_to_one_of_ideally) {
        #过滤掉不希望的
        if (my @not_masked_ids = (grep { ! $mask_devids-&gt;{$_} &amp;&amp;
                                         ! $avoid_devids-&gt;{$_}
                                     }
                                  map { $_-&gt;id } @ddevs)) {
            $ddevid = $not_masked_ids[0]; #拿一个放到ddevid
        } else {
            return $retunlock-&gt;("would_worsen");
        }
    } elsif (@ddevs = $rr-&gt;copy_to_one_of_desperate) { #没有不同的host，没办法同一个host也行啊
        # TODO: reschedule a replication for 'n' minutes in future, or
        # when new hosts/devices become available or change state
        $ddevid = $ddevs[0]-&gt;id;
    } else {
        #跳出了呀，
        last;
    }
    #标记一下真的复制了
    $got_copy_request = 1;

    # replication policy shouldn't tell us to put a file on a device
    # we've already told it that we've failed at.  so if we get that response,
    # the policy plugin is broken and we should terminate now.
    #不在错误数组里
    if ($dest_failed{$ddevid}) {
        return $retunlock-&gt;(0, "policy_error_doing_failed",
                            "replication policy told us to do something we already told it we failed at while replicating fid $fidid");
    }

    # replication policy shouldn't tell us to put a file on a
    # device that it's already on.  that's just stupid.
    #已经在这file_on上了么，不行的呀
    if (grep { $_-&gt;id == $ddevid } @on_devs) {
        return $retunlock-&gt;(0, "policy_error_already_there",
                            "replication policy told us to put fid $fidid on dev $ddevid, but it's already there!");
    }

    # find where we're replicating from
    #这里开始设置复制源
    {
        # TODO: use an observed good device+host as source to start.
        #排除掉错误源
        my @choices = grep { ! $source_failed{$_} } @on_up_devid;
        return $retunlock-&gt;(0, "source_down", "No devices available replicating $fidid") unless @choices;
        #如果有fixed_source那就用，没有么就随即选一个吧
        if ($fixed_source &amp;&amp; grep { $_ == $fixed_source } @choices) {
            $sdevid = $fixed_source;
        } else {
            @choices = List::Util::shuffle(@choices);
            MogileFS::run_global_hook('replicate_order_final_choices', $devs, \@choices);
            $sdevid = shift @choices;
        }
    }

    #是子进程的判断
    my $worker = MogileFS::ProcManager-&gt;is_child or die;
    #校验和，不用的呀，不考虑
    my $digest = Digest-&gt;new($cls-&gt;hashname) if $cls-&gt;hashtype;
    #真的复制了
    my $rv = http_copy(
                       sdevid       =&gt; $sdevid,
                       ddevid       =&gt; $ddevid,
                       fid          =&gt; $fidid,
                       rfid         =&gt; $fid,
                       expected_len =&gt; undef,  # FIXME: get this info to pass along
                       errref       =&gt; \$copy_err,
                       callback     =&gt; sub { $worker-&gt;still_alive; },
                       digest       =&gt; $digest,
                       );
    die "Bogus error code: $copy_err" if !$rv &amp;&amp; $copy_err !~ /^(?:src|dest)_error$/;
    #如果错误了，设置失败数组，next等于其他语言的continue呀，继续找其他的
    unless ($rv) {
        error("Failed copying fid $fidid from devid $sdevid to devid $ddevid (error type: $copy_err)");
        if ($copy_err eq "src_error") {
            $source_failed{$sdevid} = 1;

            if ($fixed_source &amp;&amp; $fixed_source == $sdevid) {
                error("Fixed source dev$fixed_source was requested for $fidid but failed: will try other sources");
            }

        } else {
            $dest_failed{$ddevid} = 1;
        }
        next;
    }
    #复制成功了，开始插入数据了
    my $dfid = MogileFS::DevFID-&gt;new($ddevid, $fid);
    $dfid-&gt;add_to_db;
    if ($digest &amp;&amp; !$fid-&gt;checksum) {
        $sto-&gt;set_checksum($fidid, $cls-&gt;hashtype, $digest-&gt;digest);
    }

    #设置一下变量，加入要复制3分是应该再继续复制的
    push @on_devs, $devs-&gt;{$ddevid};
    push @on_devs_tellpol, $devs-&gt;{$ddevid};
    push @on_up_devid, $ddevid;
}

# We are over replicated. Let caller decide if it should rebalance.
#好过头了
if ($rr-&gt;too_happy) {
    return $retunlock-&gt;(0, "too_happy", "fid $fidid is on too many devices");
}
#这是满足策略的情况
if ($rr-&gt;is_happy) {
    return $retunlock-&gt;(1) if $got_copy_request;
    #没有地方去复制了
    return $retunlock-&gt;("lost_race");  # some other process got to it first.  policy was happy immediately.
}
#应该不会走到这里了
return $retunlock-&gt;(0, "policy_no_suggestions",
                    "replication policy ran out of suggestions for us replicating fid $fidid");
</code></pre>

<p>}
```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[mogstored使用nginx]]></title>
    <link href="http://www.wanghd.com/blog/2012/10/13/mogstoredshi-yong-nginx/"/>
    <updated>2012-10-13T11:37:00+08:00</updated>
    <id>http://www.wanghd.com/blog/2012/10/13/mogstoredshi-yong-nginx</id>
    <content type="html"><![CDATA[<h3>配置nginx.conf</h3>

<ul>
<li>使用mogile用户，如果使用root会导致delete job无法删除(因为新文件是root的呀)</li>
</ul>


<p><code>
user mogile daemon
</code></p>

<ul>
<li>autoindex on: 必须要加，否则mogadm check显示错误，因为返回错误状态码</li>
<li>expires max: 过期头设置到2037年, and the Cache-Control max-age to 10 years.</li>
<li>client_max_body_size 20m: 放宽上传大小</li>
<li><p>client_body_temp_path xxxx: 存放零时文件的目录</p></li>
<li><p>配置WebDav,首先要确认HttpDavModule已经被加载，默认是不加载的 ./configure --with-http_dav_module</p></li>
<li>dav_methods PUT DELETE MKCOL; 允许的方法put是上传，delete是删除,mkcol是创建文件夹</li>
<li>dav_access user:rw group:r all:r; 设置权限</li>
<li>create_full_put_path on; put新文件默认只能在已存在的目录，不过这条指令允许创建所有的中间目录</li>
</ul>


<p>```
server
{</p>

<pre><code>listen 7500;
error_log /var/log/nginx/mogstore.error.log crit;
access_log /var/log/nginx/mogstore.access.log gzip;

location / {
    autoindex   on;
    root        /huida/mogdata;
}

location /dev1/ {
    expires             max;
    root                /huida/mogdata;
    client_max_body_size        20m;
    client_body_temp_path       /huida/mogdata/dev1/temp;
    dav_methods                 PUT DELETE MKCOL;
    create_full_put_path        on;
    dav_access                  user:rw group:r all:r;
}
</code></pre>

<p>}
```</p>

<h3>配置mogstored.conf</h3>

<ul>
<li>已经不需要perlbal了</li>
<li>虽然是不用server了，不过mogstored还是要启动，因为还有个磁盘监控7501端口</li>
</ul>


<p>```</p>

<h1>httplisten = 0.0.0.0:7500</h1>

<p>server = none
```</p>

<h3>结论</h3>

<ul>
<li>nginx比perlbal更稳定，基本不会挂掉了</li>
<li>mogadm device add 时不要忘记配置nginx后重启，也别忘记自己建文件夹【nginx多一步】</li>
<li>nginx配置好user,所以不会创建的文件权限为root:root,不用nginx就要用su mogile -c mogstored了</li>
</ul>

]]></content>
  </entry>
  
</feed>
